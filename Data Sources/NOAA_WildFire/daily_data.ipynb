{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from config import token\n",
    "import sqlite3\n",
    "import warnings\n",
    "import calendar\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AE000041196</th>\n",
       "      <th>20180101</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>259</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>S</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20180101</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20180101</td>\n",
       "      <td>TAVG</td>\n",
       "      <td>186</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td>20180101</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td>20180101</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td>20180101</td>\n",
       "      <td>TAVG</td>\n",
       "      <td>209</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AE000041196  20180101  TMAX  259 Unnamed: 4 Unnamed: 5  S  Unnamed: 7\n",
       "0  AE000041196  20180101  TMIN  112        NaN        NaN  S         NaN\n",
       "1  AE000041196  20180101  TAVG  186          H        NaN  S         NaN\n",
       "2  AEM00041194  20180101  TMAX  250        NaN        NaN  S         NaN\n",
       "3  AEM00041194  20180101  PRCP    0        NaN        NaN  S         NaN\n",
       "4  AEM00041194  20180101  TAVG  209          H        NaN  S         NaN"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the .csv.gz file\n",
    "csv_gz_file_path = \"Resources/2018.csv.gz\"\n",
    "\n",
    "# Read the compressed CSV file using Pandas\n",
    "df = pd.read_csv(csv_gz_file_path, compression='gzip')\n",
    "\n",
    "# Now the 'df' DataFrame contains the data from the compressed CSV file\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>data_type</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20180101</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>20180101</td>\n",
       "      <td>TAVG</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td>20180101</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td>20180101</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td>20180101</td>\n",
       "      <td>TAVG</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station      date data_type  value\n",
       "0  AE000041196  20180101      TMIN    112\n",
       "1  AE000041196  20180101      TAVG    186\n",
       "2  AEM00041194  20180101      TMAX    250\n",
       "3  AEM00041194  20180101      PRCP      0\n",
       "4  AEM00041194  20180101      TAVG    209"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['AE000041196','20180101','TMAX','259']]\n",
    "\n",
    "# Rename columns\n",
    "df = df.rename(columns={\n",
    "    'AE000041196': 'station',\n",
    "    '20180101': 'date',\n",
    "    'TMAX': 'data_type',\n",
    "    '259': 'value'\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30208386, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of values to keep\n",
    "valid_values = ['TMAX', 'TMIN', 'TAVG', 'PRCP','SNOW','SNWD','AWND']\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_df = df[df['data_type'].isin(valid_values)]\n",
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>AWND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6856</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>FMW00040308</td>\n",
       "      <td>274.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6858</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>FMW00040505</td>\n",
       "      <td>303.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7574</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>GQW00041415</td>\n",
       "      <td>306.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24719</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>USC00244558</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>-132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29864</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>USW00003017</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-113.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date      station   TMAX   TMIN   TAVG   PRCP  SNOW   SNWD  AWND\n",
       "6856  2018-01-01  FMW00040308  274.0  251.0  266.0  361.0   0.0    0.0  28.0\n",
       "6858  2018-01-01  FMW00040505  303.0  267.0  281.0   33.0   0.0    0.0  33.0\n",
       "7574  2018-01-01  GQW00041415  306.0  261.0  275.0    3.0   0.0    0.0  51.0\n",
       "24719 2018-01-01  USC00244558 -105.0 -138.0 -132.0    0.0   0.0  380.0   7.0\n",
       "29864 2018-01-01  USW00003017  -21.0 -160.0 -113.0    0.0   0.0    0.0  24.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'value' column to float, handling invalid entries as NaN\n",
    "filtered_df['value'] = pd.to_numeric(filtered_df['value'], errors='coerce')\n",
    "\n",
    "# Initialize empty lists to store the data\n",
    "dates = []\n",
    "stations = []\n",
    "tmax_values = []\n",
    "tmin_values = []\n",
    "tavg_values = []\n",
    "prcp_values = []\n",
    "snow_values = []\n",
    "snwd_values = []\n",
    "awnd_values = []\n",
    "\n",
    "# Iterate through the rows of the original DataFrame\n",
    "for index, row in filtered_df.iterrows():\n",
    "    date = row['date']\n",
    "    station = row['station']\n",
    "    datatype = row['data_type']\n",
    "    value = row['value']\n",
    "\n",
    "    if datatype == 'TMAX':\n",
    "        tmax_values.append(value)\n",
    "        tmin_values.append(None)\n",
    "        tavg_values.append(None)\n",
    "        prcp_values.append(None)\n",
    "        snow_values.append(None)\n",
    "        snwd_values.append(None)\n",
    "        awnd_values.append(None)\n",
    "    elif datatype == 'TMIN':\n",
    "        tmax_values.append(None)\n",
    "        tmin_values.append(value)\n",
    "        tavg_values.append(None)\n",
    "        prcp_values.append(None)\n",
    "        snow_values.append(None)\n",
    "        snwd_values.append(None)\n",
    "        awnd_values.append(None)\n",
    "    elif datatype == 'TAVG':\n",
    "        tmax_values.append(None)\n",
    "        tmin_values.append(None)\n",
    "        tavg_values.append(value)\n",
    "        prcp_values.append(None)\n",
    "        snow_values.append(None)\n",
    "        snwd_values.append(None)\n",
    "        awnd_values.append(None)\n",
    "    elif datatype == 'PRCP':\n",
    "        tmax_values.append(None)\n",
    "        tmin_values.append(None)\n",
    "        tavg_values.append(None)\n",
    "        prcp_values.append(value)\n",
    "        snow_values.append(None)\n",
    "        snwd_values.append(None)\n",
    "        awnd_values.append(None)\n",
    "    elif datatype == 'SNOW':\n",
    "        tmax_values.append(None)\n",
    "        tmin_values.append(None)\n",
    "        tavg_values.append(None)\n",
    "        prcp_values.append(None)\n",
    "        snow_values.append(value)\n",
    "        snwd_values.append(None)\n",
    "        awnd_values.append(None)\n",
    "    elif datatype == 'SNWD':\n",
    "        tmax_values.append(None)\n",
    "        tmin_values.append(None)\n",
    "        tavg_values.append(None)\n",
    "        prcp_values.append(None)\n",
    "        snow_values.append(None)\n",
    "        snwd_values.append(value)\n",
    "        awnd_values.append(None)\n",
    "    elif datatype == 'AWND':\n",
    "        tmax_values.append(None)\n",
    "        tmin_values.append(None)\n",
    "        tavg_values.append(None)\n",
    "        prcp_values.append(None)\n",
    "        snow_values.append(None)\n",
    "        snwd_values.append(None)\n",
    "        awnd_values.append(value)\n",
    "\n",
    "    dates.append(date)\n",
    "    stations.append(station)\n",
    "\n",
    "# Create a new DataFrame\n",
    "new_data = {\n",
    "    'date': dates,\n",
    "    'station': stations,\n",
    "    'TMAX': tmax_values,\n",
    "    'TMIN': tmin_values,\n",
    "    'TAVG': tavg_values,\n",
    "    'PRCP': prcp_values,\n",
    "    'SNOW': snow_values,\n",
    "    'SNWD': snwd_values,\n",
    "    'AWND': awnd_values\n",
    "}\n",
    "\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Group by date and station and keep non-null values\n",
    "grouped_df = new_df.groupby(['date', 'station']).first().reset_index()\n",
    "\n",
    "grouped_df = grouped_df.dropna(subset=['TMAX', 'TMIN', 'TAVG','PRCP','SNOW','SNWD','AWND']) #'SNOW','SNWD',\n",
    "\n",
    "grouped_df['date'] = pd.to_datetime(grouped_df['date'], format='%Y%m%d')\n",
    "\n",
    "# Write the grouped DataFrame to a CSV file\n",
    "csv_filename = 'Outputs/grouped_df.csv'\n",
    "grouped_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "# Print the first few rows of the filtered DataFrame\n",
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71871, 9)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>mindate</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>latitude</th>\n",
       "      <th>name</th>\n",
       "      <th>datacoverage</th>\n",
       "      <th>id</th>\n",
       "      <th>elevationUnit</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139.0</td>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>31.57020</td>\n",
       "      <td>ABBEVILLE, AL US</td>\n",
       "      <td>0.8813</td>\n",
       "      <td>COOP:010008</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-85.24820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239.6</td>\n",
       "      <td>1938-01-01</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>34.21096</td>\n",
       "      <td>ADDISON, AL US</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>COOP:010063</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-87.17838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302.1</td>\n",
       "      <td>1940-05-01</td>\n",
       "      <td>1962-03-01</td>\n",
       "      <td>34.41667</td>\n",
       "      <td>ADDISON CENTRAL TOWER, AL US</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>COOP:010071</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-87.31667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172.5</td>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>33.17835</td>\n",
       "      <td>ALABASTER SHELBY CO AIRPORT ASOS, AL US</td>\n",
       "      <td>0.8064</td>\n",
       "      <td>COOP:010116</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-86.78178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183.8</td>\n",
       "      <td>1949-01-01</td>\n",
       "      <td>1949-12-01</td>\n",
       "      <td>34.68910</td>\n",
       "      <td>BELLE MINA 2 N, AL US</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>COOP:010117</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-86.88190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   elevation     mindate     maxdate  latitude  \\\n",
       "0      139.0  1948-01-01  2014-01-01  31.57020   \n",
       "1      239.6  1938-01-01  2015-11-01  34.21096   \n",
       "2      302.1  1940-05-01  1962-03-01  34.41667   \n",
       "3      172.5  1995-04-01  2015-11-01  33.17835   \n",
       "4      183.8  1949-01-01  1949-12-01  34.68910   \n",
       "\n",
       "                                      name  datacoverage           id  \\\n",
       "0                         ABBEVILLE, AL US        0.8813  COOP:010008   \n",
       "1                           ADDISON, AL US        0.5059  COOP:010063   \n",
       "2             ADDISON CENTRAL TOWER, AL US        0.9658  COOP:010071   \n",
       "3  ALABASTER SHELBY CO AIRPORT ASOS, AL US        0.8064  COOP:010116   \n",
       "4                    BELLE MINA 2 N, AL US        1.0000  COOP:010117   \n",
       "\n",
       "  elevationUnit  longitude  \n",
       "0        METERS  -85.24820  \n",
       "1        METERS  -87.17838  \n",
       "2        METERS  -87.31667  \n",
       "3        METERS  -86.78178  \n",
       "4        METERS  -86.88190  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df = pd.read_csv('Outputs/full_station_list.csv')\n",
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 'id' column into two columns\n",
    "stations_df[['station_code', 'station_name']] = stations_df['id'].str.split(':', expand=True)\n",
    "\n",
    "# Drop the original 'id' column if needed\n",
    "stations_df = stations_df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>mindate</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>latitude</th>\n",
       "      <th>name</th>\n",
       "      <th>datacoverage</th>\n",
       "      <th>elevationUnit</th>\n",
       "      <th>longitude</th>\n",
       "      <th>station_code</th>\n",
       "      <th>station_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139.0</td>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>31.57020</td>\n",
       "      <td>ABBEVILLE, AL US</td>\n",
       "      <td>0.8813</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-85.24820</td>\n",
       "      <td>COOP</td>\n",
       "      <td>010008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239.6</td>\n",
       "      <td>1938-01-01</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>34.21096</td>\n",
       "      <td>ADDISON, AL US</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-87.17838</td>\n",
       "      <td>COOP</td>\n",
       "      <td>010063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302.1</td>\n",
       "      <td>1940-05-01</td>\n",
       "      <td>1962-03-01</td>\n",
       "      <td>34.41667</td>\n",
       "      <td>ADDISON CENTRAL TOWER, AL US</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-87.31667</td>\n",
       "      <td>COOP</td>\n",
       "      <td>010071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172.5</td>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>33.17835</td>\n",
       "      <td>ALABASTER SHELBY CO AIRPORT ASOS, AL US</td>\n",
       "      <td>0.8064</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-86.78178</td>\n",
       "      <td>COOP</td>\n",
       "      <td>010116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183.8</td>\n",
       "      <td>1949-01-01</td>\n",
       "      <td>1949-12-01</td>\n",
       "      <td>34.68910</td>\n",
       "      <td>BELLE MINA 2 N, AL US</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-86.88190</td>\n",
       "      <td>COOP</td>\n",
       "      <td>010117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   elevation     mindate     maxdate  latitude  \\\n",
       "0      139.0  1948-01-01  2014-01-01  31.57020   \n",
       "1      239.6  1938-01-01  2015-11-01  34.21096   \n",
       "2      302.1  1940-05-01  1962-03-01  34.41667   \n",
       "3      172.5  1995-04-01  2015-11-01  33.17835   \n",
       "4      183.8  1949-01-01  1949-12-01  34.68910   \n",
       "\n",
       "                                      name  datacoverage elevationUnit  \\\n",
       "0                         ABBEVILLE, AL US        0.8813        METERS   \n",
       "1                           ADDISON, AL US        0.5059        METERS   \n",
       "2             ADDISON CENTRAL TOWER, AL US        0.9658        METERS   \n",
       "3  ALABASTER SHELBY CO AIRPORT ASOS, AL US        0.8064        METERS   \n",
       "4                    BELLE MINA 2 N, AL US        1.0000        METERS   \n",
       "\n",
       "   longitude station_code station_name  \n",
       "0  -85.24820         COOP       010008  \n",
       "1  -87.17838         COOP       010063  \n",
       "2  -87.31667         COOP       010071  \n",
       "3  -86.78178         COOP       010116  \n",
       "4  -86.88190         COOP       010117  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>date</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>AWND</th>\n",
       "      <th>station_name</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GQW00041415</td>\n",
       "      <td>GUAM INTERNATIONAL AIRPORT, US</td>\n",
       "      <td>13.48333</td>\n",
       "      <td>144.80000</td>\n",
       "      <td>77.4</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>275.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>GUAM INTERNATIONAL AIRPORT</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00244558</td>\n",
       "      <td>KALISPELL GLACIER AIRPORT, MT US</td>\n",
       "      <td>48.30408</td>\n",
       "      <td>-114.26426</td>\n",
       "      <td>903.2</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>-132.0</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>KALISPELL GLACIER AIRPORT</td>\n",
       "      <td>MT US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USW00003017</td>\n",
       "      <td>DENVER INTERNATIONAL AIRPORT, CO US</td>\n",
       "      <td>39.84657</td>\n",
       "      <td>-104.65623</td>\n",
       "      <td>1647.2</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>-113.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>DENVER INTERNATIONAL AIRPORT</td>\n",
       "      <td>CO US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>USW00003812</td>\n",
       "      <td>ASHEVILLE REGIONAL AIRPORT, NC US</td>\n",
       "      <td>35.43178</td>\n",
       "      <td>-82.53787</td>\n",
       "      <td>645.6</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>ASHEVILLE REGIONAL AIRPORT</td>\n",
       "      <td>NC US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>USW00003816</td>\n",
       "      <td>PADUCAH BARKLEY REGIONAL AIRPORT, KY US</td>\n",
       "      <td>37.05635</td>\n",
       "      <td>-88.77425</td>\n",
       "      <td>124.1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>-123.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>PADUCAH BARKLEY REGIONAL AIRPORT</td>\n",
       "      <td>KY US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station                                     name  latitude  longitude  \\\n",
       "2  GQW00041415           GUAM INTERNATIONAL AIRPORT, US  13.48333  144.80000   \n",
       "3  USC00244558         KALISPELL GLACIER AIRPORT, MT US  48.30408 -114.26426   \n",
       "4  USW00003017      DENVER INTERNATIONAL AIRPORT, CO US  39.84657 -104.65623   \n",
       "5  USW00003812        ASHEVILLE REGIONAL AIRPORT, NC US  35.43178  -82.53787   \n",
       "6  USW00003816  PADUCAH BARKLEY REGIONAL AIRPORT, KY US  37.05635  -88.77425   \n",
       "\n",
       "   elevation        date   TAVG   TMAX   TMIN  PRCP  SNOW   SNWD  AWND  \\\n",
       "2       77.4  2018-01-01  275.0  306.0  261.0   3.0   0.0    0.0  51.0   \n",
       "3      903.2  2018-01-01 -132.0 -105.0 -138.0   0.0   0.0  380.0   7.0   \n",
       "4     1647.2  2018-01-01 -113.0  -21.0 -160.0   0.0   0.0    0.0  24.0   \n",
       "5      645.6  2018-01-01  -80.0  -60.0 -110.0   0.0   0.0    0.0  68.0   \n",
       "6      124.1  2018-01-01 -123.0  -82.0 -160.0   0.0   0.0    0.0  40.0   \n",
       "\n",
       "                       station_name   state  \n",
       "2        GUAM INTERNATIONAL AIRPORT      US  \n",
       "3         KALISPELL GLACIER AIRPORT   MT US  \n",
       "4      DENVER INTERNATIONAL AIRPORT   CO US  \n",
       "5        ASHEVILLE REGIONAL AIRPORT   NC US  \n",
       "6  PADUCAH BARKLEY REGIONAL AIRPORT   KY US  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the stations.csv file into stations_df\n",
    "# stations_df = pd.read_csv('full_station_list.csv')\n",
    "grouped_df= pd.read_csv('Outputs/grouped_df.csv')\n",
    "\n",
    "# Merge the two DataFrames based on 'station' using a left join\n",
    "grouped_df_detailed = pd.merge(grouped_df, stations_df, \n",
    "                               left_on='station', right_on='station_name', how='left')\n",
    "\n",
    "# Drop the redundant columns (from stations_df)\n",
    "grouped_df_detailed.drop(columns=['station_name'], inplace=True)\n",
    "\n",
    "grouped_df_detailed=grouped_df_detailed[['station','name','latitude','longitude','elevation','date','TAVG','TMAX','TMIN','PRCP','SNOW','SNWD','AWND']]\n",
    "\n",
    "# grouped_df_detailed['date'] = pd.to_datetime(grouped_df_detailed['date'], format='%Y%m%d')\n",
    "\n",
    "grouped_df_detailed[['station_name', 'state']] = grouped_df_detailed['name'].str.split(',', n=1, expand=True)\n",
    "\n",
    "# Filter out rows where state doesn't end with 'US'\n",
    "grouped_df_detailed = grouped_df_detailed[grouped_df_detailed['state'].str.strip().str.endswith('US')]\n",
    "\n",
    "# Write the grouped DataFrame to a CSV file\n",
    "csv_filename = 'Outputs/readings.csv'\n",
    "grouped_df_detailed.to_csv(csv_filename, index=False)\n",
    "\n",
    "grouped_df_detailed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71141, 15)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df_detailed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>NWCG_REPORTING_UNIT_NAME</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>FIRE_YEAR</th>\n",
       "      <th>FPA_ID</th>\n",
       "      <th>FIRE_CODE</th>\n",
       "      <th>NWCG_CAUSE_CLASSIFICATION</th>\n",
       "      <th>NWCG_GENERAL_CAUSE</th>\n",
       "      <th>FIRE_NAME</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>CONT_DATE</th>\n",
       "      <th>DISCOVERY_TIME</th>\n",
       "      <th>CONT_TIME</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>FIPS_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2045714</th>\n",
       "      <td>46.275833</td>\n",
       "      <td>-114.379167</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Bitterroot National Forest</td>\n",
       "      <td>A</td>\n",
       "      <td>2018</td>\n",
       "      <td>FS-6911076</td>\n",
       "      <td>EKS4</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Natural</td>\n",
       "      <td>BLODGETT</td>\n",
       "      <td>8/22/2018</td>\n",
       "      <td>8/22/2018</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>MT</td>\n",
       "      <td>081</td>\n",
       "      <td>30081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045715</th>\n",
       "      <td>46.404167</td>\n",
       "      <td>-113.921944</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Bitterroot National Forest</td>\n",
       "      <td>A</td>\n",
       "      <td>2018</td>\n",
       "      <td>FS-6908885</td>\n",
       "      <td>L1RX</td>\n",
       "      <td>Human</td>\n",
       "      <td>Equipment and vehicle use</td>\n",
       "      <td>CORLEY GULCH</td>\n",
       "      <td>7/26/2018</td>\n",
       "      <td>7/28/2018</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>MT</td>\n",
       "      <td>081</td>\n",
       "      <td>30081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045716</th>\n",
       "      <td>46.245833</td>\n",
       "      <td>-114.308889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bitterroot National Forest</td>\n",
       "      <td>B</td>\n",
       "      <td>2018</td>\n",
       "      <td>FS-6898061</td>\n",
       "      <td>L49X</td>\n",
       "      <td>Human</td>\n",
       "      <td>Recreation and ceremony</td>\n",
       "      <td>CANYON CREEK</td>\n",
       "      <td>9/21/2018</td>\n",
       "      <td>9/23/2018</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>MT</td>\n",
       "      <td>081</td>\n",
       "      <td>30081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045717</th>\n",
       "      <td>45.784722</td>\n",
       "      <td>-114.033056</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Bitterroot National Forest</td>\n",
       "      <td>A</td>\n",
       "      <td>2018</td>\n",
       "      <td>FS-6890683</td>\n",
       "      <td>EKS4</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Natural</td>\n",
       "      <td>MAYNARD CREEK</td>\n",
       "      <td>8/17/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MT</td>\n",
       "      <td>081</td>\n",
       "      <td>30081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045718</th>\n",
       "      <td>45.986944</td>\n",
       "      <td>-113.807222</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Bitterroot National Forest</td>\n",
       "      <td>A</td>\n",
       "      <td>2018</td>\n",
       "      <td>FS-6888073</td>\n",
       "      <td>EKS4</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Natural</td>\n",
       "      <td>BLUE</td>\n",
       "      <td>8/12/2018</td>\n",
       "      <td>8/12/2018</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1334.0</td>\n",
       "      <td>MT</td>\n",
       "      <td>081</td>\n",
       "      <td>30081.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LATITUDE   LONGITUDE  FIRE_SIZE    NWCG_REPORTING_UNIT_NAME  \\\n",
       "2045714  46.275833 -114.379167        0.1  Bitterroot National Forest   \n",
       "2045715  46.404167 -113.921944        0.1  Bitterroot National Forest   \n",
       "2045716  46.245833 -114.308889        1.0  Bitterroot National Forest   \n",
       "2045717  45.784722 -114.033056        0.1  Bitterroot National Forest   \n",
       "2045718  45.986944 -113.807222        0.1  Bitterroot National Forest   \n",
       "\n",
       "        FIRE_SIZE_CLASS  FIRE_YEAR      FPA_ID FIRE_CODE  \\\n",
       "2045714               A       2018  FS-6911076      EKS4   \n",
       "2045715               A       2018  FS-6908885      L1RX   \n",
       "2045716               B       2018  FS-6898061      L49X   \n",
       "2045717               A       2018  FS-6890683      EKS4   \n",
       "2045718               A       2018  FS-6888073      EKS4   \n",
       "\n",
       "        NWCG_CAUSE_CLASSIFICATION         NWCG_GENERAL_CAUSE      FIRE_NAME  \\\n",
       "2045714                   Natural                    Natural       BLODGETT   \n",
       "2045715                     Human  Equipment and vehicle use   CORLEY GULCH   \n",
       "2045716                     Human    Recreation and ceremony   CANYON CREEK   \n",
       "2045717                   Natural                    Natural  MAYNARD CREEK   \n",
       "2045718                   Natural                    Natural           BLUE   \n",
       "\n",
       "        DISCOVERY_DATE  CONT_DATE  DISCOVERY_TIME  CONT_TIME STATE COUNTY  \\\n",
       "2045714      8/22/2018  8/22/2018          1625.0     1740.0    MT    081   \n",
       "2045715      7/26/2018  7/28/2018          1225.0     1653.0    MT    081   \n",
       "2045716      9/21/2018  9/23/2018          1305.0     1241.0    MT    081   \n",
       "2045717      8/17/2018        NaN          1723.0        NaN    MT    081   \n",
       "2045718      8/12/2018  8/12/2018          1031.0     1334.0    MT    081   \n",
       "\n",
       "         FIPS_CODE  \n",
       "2045714    30081.0  \n",
       "2045715    30081.0  \n",
       "2045716    30081.0  \n",
       "2045717    30081.0  \n",
       "2045718    30081.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wildfire=pd.read_csv('Resources/data.csv')\n",
    "\n",
    "wildfires=wildfire[['LATITUDE', 'LONGITUDE', 'FIRE_SIZE','NWCG_REPORTING_UNIT_NAME', 'FIRE_SIZE_CLASS', 'FIRE_YEAR',\n",
    "       'FPA_ID', 'FIRE_CODE', 'NWCG_CAUSE_CLASSIFICATION',\n",
    "       'NWCG_GENERAL_CAUSE', 'FIRE_NAME', 'DISCOVERY_DATE', 'CONT_DATE',\n",
    "       'DISCOVERY_TIME', 'CONT_TIME', 'STATE', 'COUNTY', 'FIPS_CODE'\n",
    "       ]]\n",
    "wildfires=wildfires[\n",
    "    (wildfires['FIRE_YEAR'].isin([2018]))\n",
    "]\n",
    "wildfires.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_detailed=pd.read_csv('Outputs/readings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station', 'name', 'latitude', 'longitude', 'elevation', 'date', 'TAVG',\n",
       "       'TMAX', 'TMIN', 'PRCP', 'SNOW', 'SNWD', 'AWND', 'station_name',\n",
       "       'state'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df_detailed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kentr\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3652\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3653\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kentr\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kentr\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: False",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26288\\1654445195.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Iterate over each row in the filtered wildfires DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwildfires\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mnearest_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_nearest_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrouped_df_detailed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mmerged_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnearest_row\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Concatenate rows vertically\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mmerged_rows\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_row\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26288\\1654445195.py\u001b[0m in \u001b[0;36mfind_nearest_match\u001b[1;34m(row, tree, df)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnearest_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LATITUDE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LONGITUDE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mnearest_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnearest_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mfiltered_nearest_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnearest_row\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnearest_row\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DISCOVERY_DATE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfiltered_nearest_row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kentr\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kentr\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1116\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kentr\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3653\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3654\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3655\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3656\u001b[0m             \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: False"
     ]
    }
   ],
   "source": [
    "# Load or generate your data, and any other necessary preprocessing steps.\n",
    "\n",
    "# Convert dates to datetime objects\n",
    "wildfires['DISCOVERY_DATE'] = pd.to_datetime(wildfires['DISCOVERY_DATE'])\n",
    "wildfires['CONT_DATE'] = pd.to_datetime(wildfires['CONT_DATE'])\n",
    "grouped_df_detailed['date'] = pd.to_datetime(grouped_df_detailed['date'])\n",
    "\n",
    "# Create a KD-Tree for efficient nearest neighbor search\n",
    "tree_data = grouped_df_detailed[['latitude', 'longitude']].values\n",
    "tree = cKDTree(tree_data)\n",
    "\n",
    "def find_nearest_match(row, tree, df):\n",
    "    _, nearest_idx = tree.query([row['LATITUDE'], row['LONGITUDE']])\n",
    "    nearest_row = df.iloc[nearest_idx]\n",
    "    filtered_nearest_row = nearest_row[nearest_row['date'] == row['DISCOVERY_DATE']]\n",
    "    return filtered_nearest_row\n",
    "\n",
    "# Create a list to hold the merged rows\n",
    "merged_rows = []\n",
    "\n",
    "# Iterate over each row in the filtered wildfires DataFrame\n",
    "for idx, row in wildfires.iterrows():\n",
    "    nearest_row = find_nearest_match(row, tree, grouped_df_detailed)\n",
    "    merged_row = pd.concat([row, nearest_row], axis=0)  # Concatenate rows vertically\n",
    "    merged_rows.append(merged_row)\n",
    "\n",
    "# Concatenate the list of merged rows into a DataFrame\n",
    "merged_results = pd.concat(merged_rows, axis=1).T\n",
    "\n",
    "# Save the resulting DataFrame to a CSV file\n",
    "csv_filename = 'Outputs/merged_results_2019.csv'\n",
    "merged_results.to_csv(csv_filename, index=False)\n",
    "\n",
    "merged_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>FIPS_CODE</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>NWCG_CAUSE_CLASSIFICATION</th>\n",
       "      <th>NWCG_GENERAL_CAUSE</th>\n",
       "      <th>FIRE_NAME</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>date</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>AWND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.275833</td>\n",
       "      <td>-114.379167</td>\n",
       "      <td>081</td>\n",
       "      <td>30081.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Natural</td>\n",
       "      <td>BLODGETT</td>\n",
       "      <td>2018-08-22</td>\n",
       "      <td>...</td>\n",
       "      <td>-114.09376</td>\n",
       "      <td>973.8</td>\n",
       "      <td>2018-08-22</td>\n",
       "      <td>150.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.404167</td>\n",
       "      <td>-113.921944</td>\n",
       "      <td>081</td>\n",
       "      <td>30081.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "      <td>Human</td>\n",
       "      <td>Equipment and vehicle use</td>\n",
       "      <td>CORLEY GULCH</td>\n",
       "      <td>2018-07-26</td>\n",
       "      <td>...</td>\n",
       "      <td>-114.09376</td>\n",
       "      <td>973.8</td>\n",
       "      <td>2018-07-26</td>\n",
       "      <td>231.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.245833</td>\n",
       "      <td>-114.308889</td>\n",
       "      <td>081</td>\n",
       "      <td>30081.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "      <td>Human</td>\n",
       "      <td>Recreation and ceremony</td>\n",
       "      <td>CANYON CREEK</td>\n",
       "      <td>2018-09-21</td>\n",
       "      <td>...</td>\n",
       "      <td>-114.09376</td>\n",
       "      <td>973.8</td>\n",
       "      <td>2018-09-21</td>\n",
       "      <td>126.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.784722</td>\n",
       "      <td>-114.033056</td>\n",
       "      <td>081</td>\n",
       "      <td>30081.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Natural</td>\n",
       "      <td>MAYNARD CREEK</td>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-114.09376</td>\n",
       "      <td>973.8</td>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>215.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.986944</td>\n",
       "      <td>-113.807222</td>\n",
       "      <td>081</td>\n",
       "      <td>30081.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Natural</td>\n",
       "      <td>BLUE</td>\n",
       "      <td>2018-08-12</td>\n",
       "      <td>...</td>\n",
       "      <td>-114.09376</td>\n",
       "      <td>973.8</td>\n",
       "      <td>2018-08-12</td>\n",
       "      <td>252.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>46.023056</td>\n",
       "      <td>-113.799722</td>\n",
       "      <td>081</td>\n",
       "      <td>30081.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Natural</td>\n",
       "      <td>POLLYWOG</td>\n",
       "      <td>2018-08-11</td>\n",
       "      <td>...</td>\n",
       "      <td>-114.09376</td>\n",
       "      <td>973.8</td>\n",
       "      <td>2018-08-11</td>\n",
       "      <td>245.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45.913611</td>\n",
       "      <td>-114.6675</td>\n",
       "      <td>049</td>\n",
       "      <td>16049.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Natural</td>\n",
       "      <td>CEDAR</td>\n",
       "      <td>2018-07-25</td>\n",
       "      <td>...</td>\n",
       "      <td>-114.09376</td>\n",
       "      <td>973.8</td>\n",
       "      <td>2018-07-25</td>\n",
       "      <td>231.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46.121111</td>\n",
       "      <td>-114.239167</td>\n",
       "      <td>081</td>\n",
       "      <td>30081.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Natural</td>\n",
       "      <td>DOUBLE STRIKE</td>\n",
       "      <td>2018-06-08</td>\n",
       "      <td>...</td>\n",
       "      <td>-114.09376</td>\n",
       "      <td>973.8</td>\n",
       "      <td>2018-06-08</td>\n",
       "      <td>169.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45.868333</td>\n",
       "      <td>-113.804167</td>\n",
       "      <td>081</td>\n",
       "      <td>30081.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Natural</td>\n",
       "      <td>MEADOW</td>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-114.09376</td>\n",
       "      <td>973.8</td>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>215.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45.914444</td>\n",
       "      <td>-114.635278</td>\n",
       "      <td>049</td>\n",
       "      <td>16049.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Natural</td>\n",
       "      <td>MT GEORGE 2</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>...</td>\n",
       "      <td>-114.09376</td>\n",
       "      <td>973.8</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>214.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LATITUDE   LONGITUDE COUNTY FIPS_CODE FIRE_SIZE FIRE_SIZE_CLASS  \\\n",
       "0  46.275833 -114.379167    081   30081.0       0.1               A   \n",
       "1  46.404167 -113.921944    081   30081.0       0.1               A   \n",
       "2  46.245833 -114.308889    081   30081.0       1.0               B   \n",
       "3  45.784722 -114.033056    081   30081.0       0.1               A   \n",
       "4  45.986944 -113.807222    081   30081.0       0.1               A   \n",
       "5  46.023056 -113.799722    081   30081.0       0.1               A   \n",
       "6  45.913611   -114.6675    049   16049.0       0.1               A   \n",
       "7  46.121111 -114.239167    081   30081.0       0.1               A   \n",
       "8  45.868333 -113.804167    081   30081.0      0.25               A   \n",
       "9  45.914444 -114.635278    049   16049.0       0.1               A   \n",
       "\n",
       "  NWCG_CAUSE_CLASSIFICATION         NWCG_GENERAL_CAUSE      FIRE_NAME  \\\n",
       "0                   Natural                    Natural       BLODGETT   \n",
       "1                     Human  Equipment and vehicle use   CORLEY GULCH   \n",
       "2                     Human    Recreation and ceremony   CANYON CREEK   \n",
       "3                   Natural                    Natural  MAYNARD CREEK   \n",
       "4                   Natural                    Natural           BLUE   \n",
       "5                   Natural                    Natural       POLLYWOG   \n",
       "6                   Natural                    Natural          CEDAR   \n",
       "7                   Natural                    Natural  DOUBLE STRIKE   \n",
       "8                   Natural                    Natural         MEADOW   \n",
       "9                   Natural                    Natural    MT GEORGE 2   \n",
       "\n",
       "  DISCOVERY_DATE  ...  longitude elevation       date   TAVG   TMAX   TMIN  \\\n",
       "0     2018-08-22  ... -114.09376     973.8 2018-08-22  150.0  267.0   61.0   \n",
       "1     2018-07-26  ... -114.09376     973.8 2018-07-26  231.0  333.0  122.0   \n",
       "2     2018-09-21  ... -114.09376     973.8 2018-09-21  126.0  250.0   44.0   \n",
       "3     2018-08-17  ... -114.09376     973.8 2018-08-17  215.0  311.0  111.0   \n",
       "4     2018-08-12  ... -114.09376     973.8 2018-08-12  252.0  289.0  156.0   \n",
       "5     2018-08-11  ... -114.09376     973.8 2018-08-11  245.0  378.0  117.0   \n",
       "6     2018-07-25  ... -114.09376     973.8 2018-07-25  231.0  333.0  117.0   \n",
       "7     2018-06-08  ... -114.09376     973.8 2018-06-08  169.0  278.0   89.0   \n",
       "8     2018-08-17  ... -114.09376     973.8 2018-08-17  215.0  311.0  111.0   \n",
       "9     2018-07-24  ... -114.09376     973.8 2018-07-24  214.0  339.0   89.0   \n",
       "\n",
       "  PRCP SNOW SNWD  AWND  \n",
       "0  0.0  0.0  0.0  22.0  \n",
       "1  0.0  0.0  0.0  24.0  \n",
       "2  0.0  0.0  0.0  11.0  \n",
       "3  0.0  0.0  0.0  26.0  \n",
       "4  0.0  0.0  0.0  55.0  \n",
       "5  0.0  0.0  0.0  26.0  \n",
       "6  0.0  0.0  0.0  19.0  \n",
       "7  0.0  0.0  0.0  13.0  \n",
       "8  0.0  0.0  0.0  26.0  \n",
       "9  0.0  0.0  0.0  21.0  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Takes 40-45 minutes to run\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "wildfires['DISCOVERY_DATE'] = pd.to_datetime(wildfires['DISCOVERY_DATE'])\n",
    "wildfires['CONT_DATE'] = pd.to_datetime(wildfires['CONT_DATE'])\n",
    "grouped_df_detailed['date'] = pd.to_datetime(grouped_df_detailed['date'])\n",
    "\n",
    "def find_nearest_match(row, df, date_col, lat_col, lon_col):\n",
    "    date_diff = abs((df[date_col] - row['DISCOVERY_DATE']).dt.days)\n",
    "    lat_diff = abs(df[lat_col] - row['LATITUDE'])\n",
    "    lon_diff = abs(df[lon_col] - row['LONGITUDE'])\n",
    "    total_diff = date_diff + lat_diff + lon_diff\n",
    "    nearest_idx = total_diff.idxmin()\n",
    "    return df.loc[nearest_idx]\n",
    "\n",
    "# Create an empty list to hold the merged rows\n",
    "merged_rows = []\n",
    "\n",
    "# Iterate over each row in the filtered wildfires DataFrame\n",
    "for idx, row in wildfires.iterrows():\n",
    "    nearest_row = find_nearest_match(row, grouped_df_detailed, 'date', 'latitude', 'longitude')\n",
    "    merged_row = pd.concat([row, nearest_row])\n",
    "    merged_rows.append(merged_row)\n",
    "\n",
    "# Concatenate the list of merged rows into a DataFrame\n",
    "merged_results = pd.concat(merged_rows, axis=1).T\n",
    "\n",
    "merged_results=merged_results[['LATITUDE', 'LONGITUDE','COUNTY', 'FIPS_CODE','FIRE_SIZE', 'FIRE_SIZE_CLASS',\n",
    "       'NWCG_CAUSE_CLASSIFICATION', 'NWCG_GENERAL_CAUSE', 'FIRE_NAME',\n",
    "       'DISCOVERY_DATE', 'CONT_DATE', 'DISCOVERY_TIME', 'CONT_TIME', 'STATE',\n",
    "       'station', 'station_name','state', 'latitude', 'longitude', 'elevation', 'date', 'TAVG',\n",
    "       'TMAX', 'TMIN','PRCP','SNOW','SNWD','AWND']]\n",
    "\n",
    "csv_filename = 'Outputs/merged_results.csv'\n",
    "merged_results.to_csv(csv_filename, index=False)\n",
    "\n",
    "merged_results.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIRE_NAME</th>\n",
       "      <th>STATE</th>\n",
       "      <th>FIPS_CODE</th>\n",
       "      <th>FIRE_LATITUDE</th>\n",
       "      <th>FIRE_LONGITUDE</th>\n",
       "      <th>FIRE_DATE</th>\n",
       "      <th>CONTAIN_DATE</th>\n",
       "      <th>CLOSEST_STATION</th>\n",
       "      <th>STATION_STATE</th>\n",
       "      <th>STATION_LAT</th>\n",
       "      <th>...</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>AWND</th>\n",
       "      <th>DAYS_TO_CONTAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80850</th>\n",
       "      <td>325942</td>\n",
       "      <td>AZ</td>\n",
       "      <td>4013.0</td>\n",
       "      <td>33.299521</td>\n",
       "      <td>-111.813080</td>\n",
       "      <td>2018-09-02</td>\n",
       "      <td>2018-09-02</td>\n",
       "      <td>TUCSON INTERNATIONAL AIRPORT</td>\n",
       "      <td>AZ US</td>\n",
       "      <td>32.13153</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>777.6</td>\n",
       "      <td>298.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80851</th>\n",
       "      <td>53892</td>\n",
       "      <td>AZ</td>\n",
       "      <td>4013.0</td>\n",
       "      <td>33.204753</td>\n",
       "      <td>-111.678537</td>\n",
       "      <td>2018-07-07</td>\n",
       "      <td>2018-07-07</td>\n",
       "      <td>TUCSON INTERNATIONAL AIRPORT</td>\n",
       "      <td>AZ US</td>\n",
       "      <td>32.13153</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>777.6</td>\n",
       "      <td>358.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80852</th>\n",
       "      <td>249704</td>\n",
       "      <td>AZ</td>\n",
       "      <td>4013.0</td>\n",
       "      <td>33.851074</td>\n",
       "      <td>-112.148687</td>\n",
       "      <td>2018-07-07</td>\n",
       "      <td>2018-07-07</td>\n",
       "      <td>TUCSON INTERNATIONAL AIRPORT</td>\n",
       "      <td>AZ US</td>\n",
       "      <td>32.13153</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>777.6</td>\n",
       "      <td>358.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80853</th>\n",
       "      <td>188245</td>\n",
       "      <td>AZ</td>\n",
       "      <td>4027.0</td>\n",
       "      <td>32.698503</td>\n",
       "      <td>-114.603127</td>\n",
       "      <td>2018-07-07</td>\n",
       "      <td>2018-07-07</td>\n",
       "      <td>MCCARRAN INTERNATIONAL AIRPORT</td>\n",
       "      <td>NV US</td>\n",
       "      <td>36.07190</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>662.8</td>\n",
       "      <td>386.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80854</th>\n",
       "      <td>4809</td>\n",
       "      <td>AZ</td>\n",
       "      <td>4013.0</td>\n",
       "      <td>33.424078</td>\n",
       "      <td>-112.252009</td>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>TUCSON INTERNATIONAL AIRPORT</td>\n",
       "      <td>AZ US</td>\n",
       "      <td>32.13153</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>777.6</td>\n",
       "      <td>154.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80855</th>\n",
       "      <td>TURNPIKE RD/BALAZS RD</td>\n",
       "      <td>CT</td>\n",
       "      <td>9013.0</td>\n",
       "      <td>41.885375</td>\n",
       "      <td>-72.261468</td>\n",
       "      <td>2018-11-17</td>\n",
       "      <td>2018-11-17</td>\n",
       "      <td>HARTFORD BRADLEY INTERNATIONAL AIRPORT</td>\n",
       "      <td>CT US</td>\n",
       "      <td>41.93742</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>51.6</td>\n",
       "      <td>38.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80856</th>\n",
       "      <td>21 PLYMOUTH ROAD</td>\n",
       "      <td>CT</td>\n",
       "      <td>9013.0</td>\n",
       "      <td>41.985374</td>\n",
       "      <td>-72.446195</td>\n",
       "      <td>2018-12-12</td>\n",
       "      <td>2018-12-12</td>\n",
       "      <td>HARTFORD BRADLEY INTERNATIONAL AIRPORT</td>\n",
       "      <td>CT US</td>\n",
       "      <td>41.93742</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>51.6</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80857</th>\n",
       "      <td>257 STAGECOACH ROAD</td>\n",
       "      <td>CT</td>\n",
       "      <td>9007.0</td>\n",
       "      <td>41.459430</td>\n",
       "      <td>-72.662758</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>HARTFORD BRADLEY INTERNATIONAL AIRPORT</td>\n",
       "      <td>CT US</td>\n",
       "      <td>41.93742</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>51.6</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80858</th>\n",
       "      <td>KINGS HWY AND GOOSE HILL RD</td>\n",
       "      <td>CT</td>\n",
       "      <td>9007.0</td>\n",
       "      <td>41.435494</td>\n",
       "      <td>-72.359669</td>\n",
       "      <td>2018-04-23</td>\n",
       "      <td>2018-04-23</td>\n",
       "      <td>HARTFORD BRADLEY INTERNATIONAL AIRPORT</td>\n",
       "      <td>CT US</td>\n",
       "      <td>41.93742</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>51.6</td>\n",
       "      <td>98.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80859</th>\n",
       "      <td>36 GREEN LANE</td>\n",
       "      <td>CT</td>\n",
       "      <td>9007.0</td>\n",
       "      <td>41.481765</td>\n",
       "      <td>-72.681206</td>\n",
       "      <td>2018-11-09</td>\n",
       "      <td>2018-11-09</td>\n",
       "      <td>HARTFORD BRADLEY INTERNATIONAL AIRPORT</td>\n",
       "      <td>CT US</td>\n",
       "      <td>41.93742</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>51.6</td>\n",
       "      <td>29.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         FIRE_NAME STATE  FIPS_CODE  FIRE_LATITUDE  \\\n",
       "80850                       325942    AZ     4013.0      33.299521   \n",
       "80851                        53892    AZ     4013.0      33.204753   \n",
       "80852                       249704    AZ     4013.0      33.851074   \n",
       "80853                       188245    AZ     4027.0      32.698503   \n",
       "80854                         4809    AZ     4013.0      33.424078   \n",
       "80855        TURNPIKE RD/BALAZS RD    CT     9013.0      41.885375   \n",
       "80856             21 PLYMOUTH ROAD    CT     9013.0      41.985374   \n",
       "80857          257 STAGECOACH ROAD    CT     9007.0      41.459430   \n",
       "80858  KINGS HWY AND GOOSE HILL RD    CT     9007.0      41.435494   \n",
       "80859                36 GREEN LANE    CT     9007.0      41.481765   \n",
       "\n",
       "       FIRE_LONGITUDE  FIRE_DATE CONTAIN_DATE  \\\n",
       "80850     -111.813080 2018-09-02   2018-09-02   \n",
       "80851     -111.678537 2018-07-07   2018-07-07   \n",
       "80852     -112.148687 2018-07-07   2018-07-07   \n",
       "80853     -114.603127 2018-07-07   2018-07-07   \n",
       "80854     -112.252009 2018-01-06   2018-01-06   \n",
       "80855      -72.261468 2018-11-17   2018-11-17   \n",
       "80856      -72.446195 2018-12-12   2018-12-12   \n",
       "80857      -72.662758 2018-04-16   2018-04-16   \n",
       "80858      -72.359669 2018-04-23   2018-04-23   \n",
       "80859      -72.681206 2018-11-09   2018-11-09   \n",
       "\n",
       "                              CLOSEST_STATION STATION_STATE  STATION_LAT  ...  \\\n",
       "80850            TUCSON INTERNATIONAL AIRPORT         AZ US     32.13153  ...   \n",
       "80851            TUCSON INTERNATIONAL AIRPORT         AZ US     32.13153  ...   \n",
       "80852            TUCSON INTERNATIONAL AIRPORT         AZ US     32.13153  ...   \n",
       "80853          MCCARRAN INTERNATIONAL AIRPORT         NV US     36.07190  ...   \n",
       "80854            TUCSON INTERNATIONAL AIRPORT         AZ US     32.13153  ...   \n",
       "80855  HARTFORD BRADLEY INTERNATIONAL AIRPORT         CT US     41.93742  ...   \n",
       "80856  HARTFORD BRADLEY INTERNATIONAL AIRPORT         CT US     41.93742  ...   \n",
       "80857  HARTFORD BRADLEY INTERNATIONAL AIRPORT         CT US     41.93742  ...   \n",
       "80858  HARTFORD BRADLEY INTERNATIONAL AIRPORT         CT US     41.93742  ...   \n",
       "80859  HARTFORD BRADLEY INTERNATIONAL AIRPORT         CT US     41.93742  ...   \n",
       "\n",
       "       FIRE_SIZE_CLASS ELEVATION   TAVG   TMAX   TMIN   PRCP  SNOW   SNWD  \\\n",
       "80850                A     777.6  298.0  339.0  200.0   81.0   0.0    0.0   \n",
       "80851                A     777.6  358.0  417.0  294.0    0.0   0.0    0.0   \n",
       "80852                A     777.6  358.0  417.0  294.0    0.0   0.0    0.0   \n",
       "80853                A     662.8  386.0  428.0  339.0    0.0   0.0    0.0   \n",
       "80854                A     777.6  154.0  250.0   83.0    0.0   0.0    0.0   \n",
       "80855                A      51.6   38.0   72.0    0.0    0.0   0.0  130.0   \n",
       "80856                A      51.6  -11.0   39.0  -66.0    0.0   0.0    0.0   \n",
       "80857                A      51.6   21.0   67.0   -5.0  546.0  15.0   30.0   \n",
       "80858                A      51.6   98.0  200.0  -10.0    0.0   0.0    0.0   \n",
       "80859                A      51.6   29.0   72.0  -27.0  183.0   0.0    0.0   \n",
       "\n",
       "       AWND  DAYS_TO_CONTAIN  \n",
       "80850  39.0                0  \n",
       "80851  39.0                0  \n",
       "80852  39.0                0  \n",
       "80853  31.0                0  \n",
       "80854  31.0                0  \n",
       "80855  38.0                0  \n",
       "80856  34.0                0  \n",
       "80857  45.0                0  \n",
       "80858  29.0                0  \n",
       "80859  30.0                0  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Read the CSV file\n",
    "merged_results = pd.read_csv('Outputs/merged_results_2018.csv')\n",
    "\n",
    "# Select specific columns from the DataFrame\n",
    "us_data = merged_results[['FIRE_NAME', 'STATE', 'FIPS_CODE', 'LATITUDE', 'LONGITUDE', 'DISCOVERY_DATE', 'CONT_DATE', 'station_name','state', 'latitude', 'longitude', 'date',\n",
    "                                    'NWCG_CAUSE_CLASSIFICATION', 'FIRE_SIZE', 'FIRE_SIZE_CLASS',\n",
    "                                    'elevation', 'TAVG', 'TMAX', 'TMIN', 'PRCP','SNOW','SNWD','AWND']]\n",
    "\n",
    "# Rename the columns\n",
    "us_data.columns = ['FIRE_NAME', 'STATE', 'FIPS_CODE', 'FIRE_LATITUDE', 'FIRE_LONGITUDE', 'FIRE_DATE', 'CONTAIN_DATE', 'CLOSEST_STATION', 'STATION_STATE', \n",
    "                             'STATION_LAT', 'STATION_LON', 'READINGS_DATE',\n",
    "                             'CAUSE_CLASSIFICATION', 'FIRE_SIZE', 'FIRE_SIZE_CLASS',\n",
    "                             'ELEVATION', 'TAVG', 'TMAX', 'TMIN', 'PRCP','SNOW','SNWD','AWND']\n",
    "\n",
    "# Convert 'CONTAIN_DATE' and 'FIRE_DATE' columns to datetime\n",
    "us_data['CONTAIN_DATE'] = pd.to_datetime(us_data['CONTAIN_DATE'])\n",
    "us_data['FIRE_DATE'] = pd.to_datetime(us_data['FIRE_DATE'])\n",
    "\n",
    "# Calculate the difference between 'CONTAIN_DATE' and 'FIRE_DATE'\n",
    "us_data['DAYS_TO_CONTAIN'] = (us_data['CONTAIN_DATE'] - us_data_2018_test['FIRE_DATE']).dt.days\n",
    "\n",
    "# Replace any NaN values in 'DAYS_TO_CONTAIN' with 1\n",
    "us_data['DAYS_TO_CONTAIN'].fillna(0, inplace=True)\n",
    "\n",
    "# Define float and int columns\n",
    "float_columns = {\n",
    "    'FIRE_LATITUDE': float,\n",
    "    'FIRE_LONGITUDE': float,\n",
    "    'STATION_LAT': float,\n",
    "    'STATION_LON': float,\n",
    "    'FIRE_SIZE': float,\n",
    "    'ELEVATION': float,\n",
    "    'TAVG': float,\n",
    "    'TMAX': float,\n",
    "    'TMIN': float,\n",
    "    'PRCP': float\n",
    "}\n",
    "\n",
    "int_columns = {\n",
    "    'DAYS_TO_CONTAIN': int,\n",
    "}\n",
    "\n",
    "# Convert columns to the specified data types\n",
    "us_data = us_data.astype({**float_columns, **int_columns})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = 'Outputs/Annual_data/us_data_2017.csv'\n",
    "us_data.to_csv(csv_filename, index=False)\n",
    "\n",
    "# Display the last 20 rows of the DataFrame\n",
    "us_data.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
